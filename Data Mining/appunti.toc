\contentsline {section}{\numberline {1}KDD process}{4}{section.1}%
\contentsline {subsection}{\numberline {1.1}Steps del KDD}{7}{subsection.1.1}%
\contentsline {subsubsection}{\numberline {1.1.1}Business Understanding}{7}{subsubsection.1.1.1}%
\contentsline {subsubsection}{\numberline {1.1.2}Data Understanding}{9}{subsubsection.1.1.2}%
\contentsline {subsubsection}{\numberline {1.1.3}Data Preparation}{10}{subsubsection.1.1.3}%
\contentsline {subsubsection}{\numberline {1.1.4}Modeling}{18}{subsubsection.1.1.4}%
\contentsline {subsubsection}{\numberline {1.1.5}Valutazione}{20}{subsubsection.1.1.5}%
\contentsline {subsubsection}{\numberline {1.1.6}Deployment}{21}{subsubsection.1.1.6}%
\contentsline {section}{\numberline {2}Learning sets of rules}{22}{section.2}%
\contentsline {subsection}{\numberline {2.1}Classificatore basato su regole}{22}{subsection.2.1}%
\contentsline {section}{\numberline {3}K-Means}{31}{section.3}%
\contentsline {section}{\numberline {4}Decision Trees}{33}{section.4}%
\contentsline {subsection}{\numberline {4.1}Affrontare i valori mancanti (missing values)}{34}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Svantaggi}{35}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Training set vs. Validation set}{36}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}Metodi di selezione dei cicli}{36}{subsection.4.4}%
\contentsline {subsubsection}{\numberline {4.4.1}Reduced error pruning (REP)}{36}{subsubsection.4.4.1}%
\contentsline {subsubsection}{\numberline {4.4.2}Minimal Error Pruning (MEP)}{36}{subsubsection.4.4.2}%
\contentsline {subsubsection}{\numberline {4.4.3}Pessimistic Error Pruning (PEP)}{37}{subsubsection.4.4.3}%
\contentsline {subsubsection}{\numberline {4.4.4}Error-Based Pruning (EBP)}{37}{subsubsection.4.4.4}%
\contentsline {section}{\numberline {5}Naive Bayes Classifier - Classificatore Bayesiano}{38}{section.5}%
\contentsline {subsection}{\numberline {5.1}Underflow Prevention}{43}{subsection.5.1}%
\contentsline {section}{\numberline {6}I modelli di regressione}{47}{section.6}%
\contentsline {subsection}{\numberline {6.1}Notazione matriciale}{53}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}Regressione con funzioni a gradini}{53}{subsection.6.2}%
\contentsline {subsubsection}{\numberline {6.2.1}Funzioni costanti a tratti per la regressione semplice}{54}{subsubsection.6.2.1}%
\contentsline {subsubsection}{\numberline {6.2.2}Alberi di regressione}{54}{subsubsection.6.2.2}%
\contentsline {subsubsection}{\numberline {6.2.3}Individuazione della sequenza di suddivisioni ottimali (crescita dell'albero)}{55}{subsubsection.6.2.3}%
\contentsline {subsubsection}{\numberline {6.2.4}Estensione al caso di due o pi√π regressori continui}{56}{subsubsection.6.2.4}%
\contentsline {subsubsection}{\numberline {6.2.5}X ordinale}{56}{subsubsection.6.2.5}%
\contentsline {subsubsection}{\numberline {6.2.6}X nominale}{56}{subsubsection.6.2.6}%
\contentsline {subsection}{\numberline {6.3}Induzione dell'albero del modello graduale}{56}{subsection.6.3}%
\contentsline {section}{\numberline {7}Associazioni tra variabili}{60}{section.7}%
\contentsline {subsection}{\numberline {7.1}Data mining descrittivo - Trovare le diendeze tra variabili}{60}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Association rules discovery}{62}{subsection.7.2}%
